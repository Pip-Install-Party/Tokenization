# Program 2 - Tokenization

This program will identify and remove comments from an input test file using a deterministic finite state automoton (DFA) before using a DFA to convert the input file into a series of tokens.

Authored by: [Blake Marshall](https://github.com/officialblake), [Brandon Robinson](https://github.com/brandonuscg), [Holden Ea](https://github.com/holdenkea), [Rolando Yax](https://github.com/Ryax3), and [Jacob Sellers](https://github.com/JacobS999)

## Running the program: 

This project can be run via make.

```make```

```./tokenize.x```

If you have a Windows based machine, you will need to adjust the Makefile to generate a ```.exe``` executable, rather than ```.x```.
